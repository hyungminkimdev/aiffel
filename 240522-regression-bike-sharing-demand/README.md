<aside>
ğŸ”‘ **PRT(Peer Review Template)**

ì‘ì„±ì : ê¹€ì„±ì—°

- [ ]  **1. ì£¼ì–´ì§„ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì™„ì„±ëœ ì½”ë“œê°€ ì œì¶œë˜ì—ˆë‚˜ìš”? (ì™„ì„±ë„)**
    - ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” ìµœì¢… ê²°ê³¼ë¬¼ì´ ì²¨ë¶€ë˜ì—ˆëŠ”ì§€ í™•ì¸
    - ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì™„ì„±ëœ ì½”ë“œë€ í”„ë¡œì íŠ¸ ë£¨ë¸Œë¦­ 3ê°œ ì¤‘ 2ê°œ, 
    í€˜ìŠ¤íŠ¸ ë¬¸ì œ ìš”êµ¬ì¡°ê±´ ë“±ì„ ì§€ì¹­
        - í•´ë‹¹ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë¶€ë¶„ì˜ ì½”ë“œ ë° ê²°ê³¼ë¬¼ì„ ìº¡ì³í•˜ì—¬ ì‚¬ì§„ìœ¼ë¡œ ì²¨ë¶€
![img](reason1.png)
- ì½”ë“œë¥¼ ë§‰ ê³ ì³ë„ ë ì§€ ëª¨ë¥´ê² ë„¤ìš”
    - test dataì—ì„œ weather 4ë¥¼ ì²˜ë¦¬í•´ì£¼ë©´ ì˜ ëŒì•„ê°ˆ ê²ƒ ê°™ìŠµë‹ˆë‹¤

- [ ]  **2. í”„ë¡œì íŠ¸ì—ì„œ í•µì‹¬ì ì¸ ë¶€ë¶„ì— ëŒ€í•œ ì„¤ëª…ì´ ì£¼ì„(ë‹¥ìŠ¤íŠ¸ë§) ë° ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì˜ ê¸°ë¡ë˜ì–´ìˆë‚˜ìš”? (ì„¤ëª…)**
    - [ ]  ëª¨ë¸ ì„ ì • ì´ìœ 
    - [ ]  Metrics ì„ ì • ì´ìœ 
    - [ ]  Loss ì„ ì • ì´ìœ 


- [ ]  **3. ì²´í¬ë¦¬ìŠ¤íŠ¸ì— í•´ë‹¹í•˜ëŠ” í•­ëª©ë“¤ì„ ëª¨ë‘ ìˆ˜í–‰í•˜ì˜€ë‚˜ìš”? (ë¬¸ì œ í•´ê²°)**
    - [o]  ë°ì´í„°ë¥¼ ë¶„í• í•˜ì—¬ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í–ˆë‚˜ìš”? (train, validation, test ë°ì´í„°ë¡œ êµ¬ë¶„)
    - [ ]  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë³€ê²½í•´ê°€ë©° ì—¬ëŸ¬ ì‹œë„ë¥¼ í–ˆë‚˜ìš”? (learning rate, dropout rate, unit, batch size, epoch ë“±)
    - [o]  ê° ì‹¤í—˜ì„ ì‹œê°í™”í•˜ì—¬ ë¹„êµí•˜ì˜€ë‚˜ìš”?
    - [ ]  ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ê°€ ê¸°ë¡ë˜ì—ˆë‚˜ìš”?

- IQRì´ ë‘ê°€ì§€ í•­ëª©ì—ì„œ ë„˜ì–´ê°€ë©´ outlierë¡œ ì²˜ë¦¬í•´ì„œ ë„ˆë¬´ ë§ì€ ë°ì´í„°ê°€ ì†ì‹¤ë˜ì§€ ì•Šë„ë¡ í•œ ì ì´ ì¸ìƒ ê¹ŠìŠµë‹ˆë‹¤.

```python
# IQR method
import numpy as np
from collections import Counter

def detect_outliers(data, n, cols):
    outlier_indices = []
    for col in cols:
        Q1 = np.percentile(data[col], 25)
        Q3 = np.percentile(data[col], 75)
        IQR = Q3 - Q1

        outlier_step = 1.5 * IQR

        outlier_list_col = data[(data[col] < Q1 - outlier_step) | (data[col] > Q3 + outlier_step)].index
        outlier_indices.extend(outlier_list_col)
    outlier_indices = Counter(outlier_indices)
    multiple_outliers = list(k for k, v in outlier_indices.items() if v > n)

    return multiple_outliers

Outliers_to_drop = detect_outliers(train, 2, ["temp", "atemp", "casual", "registered", "humidity", "windspeed", "count"])
```
- ì œê°€ ê³ ë¯¼ í–ˆë˜ 0ì„ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì•„ì´ë””ì–´ë¥¼ ë³¼ ìˆ˜ ìˆì–´ì„œ í¥ë¯¸ë¡œì› ìŠµë‹ˆë‹¤
```python
from sklearn.ensemble import RandomForestClassifier

def predict_windspeed(data):
    wind0 = data.loc[data['windspeed'] == 0]
    windnot0 = data.loc[data['windspeed'] != 0]

    # Predict 'windspeed' using weather variables
    col = ['season', 'weather', 'temp', 'humidity', 'atemp', 'day']

    windnot0['windspeed'] = windnot0['windspeed'].astype('str')

    rf = RandomForestClassifier()
    # Fit 'windspeed!=0'
    # model.fit(X_train, Y_train)
    rf.fit(windnot0[col], windnot0['windspeed'])

    # Predict where 'windspeed!=0'
    # model.predict(X_test)
    pred_wind0 = rf.predict(X=wind0[col])

    # Change value of 'wind0' to 'pred_wind0'
    wind0['windspeed'] = pred_wind0

    # Combine 'windnot0' & 'wind0'
    data = windnot0.append(wind0)
    data['windspeed'] = data['windspeed'].astype('float')

    data.reset_index(inplace=True, drop=True)

    return data
```
- ì „ì²˜ë¦¬ ê³¼ì •ë³„ë¡œ í•¨ìˆ˜ë¡œ ì •ë¦¬í•´ë†“ìœ¼ì…”ì„œ ë³´ê¸° í¸í–ˆìŠµë‹ˆë‹¤.


- [o]  **4. í”„ë¡œì íŠ¸ì— ëŒ€í•œ íšŒê³ ê°€ ìƒì„¸íˆ ê¸°ë¡ ë˜ì–´ ìˆë‚˜ìš”? (íšŒê³ , ì •ë¦¬)**
    - [o]  ë°°ìš´ ì 
    - [o]  ì•„ì‰¬ìš´ ì 
    - [o]  ëŠë‚€ ì 
    - [o]  ì–´ë ¤ì› ë˜ ì 
</aside>